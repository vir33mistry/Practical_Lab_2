{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3884b32c",
   "metadata": {},
   "source": [
    "# Diabetes Progression Risk Prediction — Model Comparison Report (Scikit‑Learn Diabetes Dataset)\n",
    "\n",
    "**Course Lab Notebook (Train / Validation / Test split + multiple models)**\n",
    "\n",
    "**Objective (screening tool):** build a model that **best predicts diabetes disease progression one year after baseline**, so physicians can flag patients at higher risk.\n",
    "\n",
    "**Models evaluated**\n",
    "1. Univariate Polynomial Regression (BMI only)\n",
    "2. Multivariate Polynomial Models (all features)\n",
    "3. Decision Trees\n",
    "4. k‑Nearest Neighbors (kNN)\n",
    "5. Logistic Regression (classification framing: “high risk” vs “low risk”)\n",
    "\n",
    "**Metrics**\n",
    "- Regression: **R²**, **MAE**, **MAPE**\n",
    "- Classification (Logistic Regression section): **Accuracy, Precision/Recall, ROC‑AUC, Log‑Loss**  \n",
    "  > Logistic Regression is a *classifier* (workshop topic). Because the original target is continuous, we create a binary “high risk” label for this section and use classification metrics.\n",
    "\n",
    "---\n",
    "\n",
    "## Notebook structure (good ML report)\n",
    "- Problem framing + metrics rationale\n",
    "- EDA (statistics, plots, correlation, insights)\n",
    "- Data quality & cleaning notes\n",
    "- Train/Validation/Test split (75/10/15)\n",
    "- Model training + validation comparison tables\n",
    "- Final test evaluation for chosen models\n",
    "- Error analysis + limitations + conclusions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b532bb0",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m datasets\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmodel_selection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[32m      8\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "# --- Setup ---\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression, Ridge, LogisticRegression\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "# Classification metrics (for Logistic Regression section)\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, roc_auc_score, log_loss,\n",
    "    confusion_matrix, ConfusionMatrixDisplay, RocCurveDisplay\n",
    ")\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "\n",
    "\n",
    "def mape(y_true, y_pred, epsilon=1e-8):\n",
    "    \"\"\"Mean Absolute Percentage Error (MAPE) with epsilon to avoid division by zero.\"\"\"\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    denom = np.maximum(np.abs(y_true), epsilon)\n",
    "    return np.mean(np.abs((y_true - y_pred) / denom)) * 100\n",
    "\n",
    "\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    return {\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"MAPE(%)\": mape(y_true, y_pred),\n",
    "    }\n",
    "\n",
    "print(\"Libraries imported.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bba05d",
   "metadata": {},
   "source": [
    "# Part 1 — Data, Problem Framing, EDA, Cleaning, Split\n",
    "\n",
    "## 1) Get the data\n",
    "We use **Scikit‑Learn’s Diabetes toy dataset** (`load_diabetes`).  \n",
    "\n",
    "## 2) Frame the problem (talking points)\n",
    "- **What we predict:** *disease progression one year after baseline* (continuous target).  \n",
    "- **Why this matters:** A model with good generalization can help physicians prioritize follow‑ups and interventions.  \n",
    "- **Train/Validation/Test thinking:**  \n",
    "  - **Train** fits model parameters.  \n",
    "  - **Validation** selects model complexity (e.g., polynomial degree, `k` in kNN, `max_depth` in trees).  \n",
    "  - **Test** is the final unbiased estimate of performance.\n",
    "\n",
    "### Metrics rationale (from the “Performance Metrics” workshop)\n",
    "- **R²:** how much variance in progression is explained by the model (higher is better).  \n",
    "- **MAE:** average absolute error in the target units (lower is better; interpretable).  \n",
    "- **MAPE:** error as a percentage (lower is better; easy to communicate, but sensitive to values near 0).\n",
    "\n",
    "### Modeling mindset (talking points from KNN + Logistic Regression workshops)\n",
    "- **kNN intuition:** “predict like your neighbors” — works well when similar patients have similar outcomes; sensitive to `k` (bias/variance trade‑off).  \n",
    "- **Logistic Regression intuition:** models probability of a **binary outcome** using a linear decision boundary in feature space; interpretable coefficients.  \n",
    "  - In this lab, the original target is continuous, so we also show a **binary high‑risk** framing for Logistic Regression (Part 3) to connect with workshop learning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7d653d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the diabetes dataset as a pandas DataFrame\n",
    "diabetes = datasets.load_diabetes(as_frame=True)\n",
    "X = diabetes.data.copy()\n",
    "y = diabetes.target.copy()\n",
    "\n",
    "print(\"Feature matrix shape:\", X.shape)\n",
    "print(\"Target shape:\", y.shape)\n",
    "display(X.head())\n",
    "display(y.head())\n",
    "\n",
    "# Dataset description (skim key parts)\n",
    "print(diabetes.DESCR[:1200], \"...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "766a6195",
   "metadata": {},
   "source": [
    "## 3) Exploratory Data Analysis (EDA)\n",
    "\n",
    "We will include:\n",
    "- Descriptive statistics\n",
    "- Histograms (feature distributions)\n",
    "- Scatter plots (BMI vs target + a couple more)\n",
    "- Correlation matrix heatmap\n",
    "- Concise insights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4065f822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Descriptive statistics\n",
    "display(X.describe().T)\n",
    "\n",
    "# Check target distribution\n",
    "plt.figure()\n",
    "plt.hist(y, bins=25)\n",
    "plt.title(\"Target distribution: disease progression (1 year)\")\n",
    "plt.xlabel(\"Progression (target)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Histograms for features\n",
    "X.hist(bins=20, figsize=(12, 8))\n",
    "plt.suptitle(\"Feature distributions (standardized features)\", y=1.02)\n",
    "plt.show()\n",
    "\n",
    "# Scatter plots (BMI, BP, and S5 vs target as examples)\n",
    "for col in [\"bmi\", \"bp\", \"s5\"]:\n",
    "    plt.figure()\n",
    "    plt.scatter(X[col], y, alpha=0.7)\n",
    "    plt.title(f\"Scatter: {col} vs target\")\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel(\"Progression (target)\")\n",
    "    plt.show()\n",
    "\n",
    "# Correlation matrix\n",
    "corr = X.join(y.rename(\"target\")).corr(numeric_only=True)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(corr, aspect=\"auto\")\n",
    "plt.title(\"Correlation matrix (features + target)\")\n",
    "plt.xticks(range(len(corr.columns)), corr.columns, rotation=90)\n",
    "plt.yticks(range(len(corr.index)), corr.index)\n",
    "plt.colorbar()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Quick look: correlations with target\n",
    "target_corr = corr[\"target\"].sort_values(ascending=False)\n",
    "display(target_corr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196a1eb8",
   "metadata": {},
   "source": [
    "### EDA Insights (concise)\n",
    "- Features are already **standardized** in this dataset (centered/scaled), which is helpful for distance‑based models (kNN) and numerical stability.\n",
    "- **BMI** and **S5** often show relatively stronger correlation with the target than many other features, suggesting they may be informative predictors.\n",
    "- Correlation does **not** guarantee causation; it’s only a first signal for modeling choices.\n",
    "- The target distribution is continuous with a moderate spread; extreme values exist, which can challenge simple linear models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3bbfa8f",
   "metadata": {},
   "source": [
    "## 4) Data Cleaning (if needed)\n",
    "\n",
    "We check for:\n",
    "- Missing values\n",
    "- Duplicates (rare in toy data)\n",
    "- Data types\n",
    "\n",
    "If no issues are found, we document that no cleaning is required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4b1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values\n",
    "missing = X.isna().sum()\n",
    "print(\"Missing values per feature:\")\n",
    "display(missing)\n",
    "\n",
    "print(\"Any missing in target?\", y.isna().any())\n",
    "\n",
    "# Duplicates (rows)\n",
    "dup_count = X.duplicated().sum()\n",
    "print(\"Duplicate feature rows:\", dup_count)\n",
    "\n",
    "# Data types\n",
    "display(X.dtypes)\n",
    "\n",
    "# Cleaning decision\n",
    "if missing.sum() == 0 and not y.isna().any():\n",
    "    print(\"✅ No missing values detected. No imputation required.\")\n",
    "else:\n",
    "    print(\"⚠️ Missing values exist — would require imputation (not expected for this dataset).\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da5cd701",
   "metadata": {},
   "source": [
    "## 5) Train / Validation / Test split (75% / 10% / 15%)\n",
    "\n",
    "We will do a two‑step split:\n",
    "1. Train (75%) vs Temp (25%)\n",
    "2. Split Temp into Validation (10%) and Test (15%)  \n",
    "   - Within the 25% temp: validation fraction = 10/25 = 0.4, test fraction = 15/25 = 0.6\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adf1b1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: train vs temp\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.25, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Step 2: temp -> validation and test\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.60, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape[0], \" (expected ~75%)\")\n",
    "print(\"Val size:  \", X_val.shape[0], \" (expected ~10%)\")\n",
    "print(\"Test size: \", X_test.shape[0], \" (expected ~15%)\")\n",
    "\n",
    "# Sanity check: proportions\n",
    "n = len(X)\n",
    "print(\"Train %:\", round(len(X_train)/n*100, 2))\n",
    "print(\"Val   %:\", round(len(X_val)/n*100, 2))\n",
    "print(\"Test  %:\", round(len(X_test)/n*100, 2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1799c95a",
   "metadata": {},
   "source": [
    "# Part 2 — Univariate Polynomial Regression (BMI only)\n",
    "\n",
    "We fit **6 models** using only the **BMI** feature:\n",
    "- Degree 0, 1, 2, 3, 4, 5\n",
    "\n",
    "Then we compare using Train + Validation metrics, pick the best model, test it, plot fits, write the equation, and analyze parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad8c7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare univariate data (BMI only)\n",
    "X_train_bmi = X_train[[\"bmi\"]].copy()\n",
    "X_val_bmi   = X_val[[\"bmi\"]].copy()\n",
    "X_test_bmi  = X_test[[\"bmi\"]].copy()\n",
    "\n",
    "results = []\n",
    "\n",
    "models = {}\n",
    "for deg in range(0, 6):\n",
    "    model = Pipeline(steps=[\n",
    "        (\"poly\", PolynomialFeatures(degree=deg, include_bias=True)),\n",
    "        (\"linreg\", LinearRegression())\n",
    "    ])\n",
    "    model.fit(X_train_bmi, y_train)\n",
    "    models[deg] = model\n",
    "\n",
    "    # Train metrics\n",
    "    yhat_tr = model.predict(X_train_bmi)\n",
    "    tr_m = regression_metrics(y_train, yhat_tr)\n",
    "\n",
    "    # Validation metrics\n",
    "    yhat_val = model.predict(X_val_bmi)\n",
    "    val_m = regression_metrics(y_val, yhat_val)\n",
    "\n",
    "    results.append({\n",
    "        \"degree\": deg,\n",
    "        \"train_R2\": tr_m[\"R2\"],\n",
    "        \"train_MAE\": tr_m[\"MAE\"],\n",
    "        \"train_MAPE(%)\": tr_m[\"MAPE(%)\"],\n",
    "        \"val_R2\": val_m[\"R2\"],\n",
    "        \"val_MAE\": val_m[\"MAE\"],\n",
    "        \"val_MAPE(%)\": val_m[\"MAPE(%)\"],\n",
    "        \"n_params\": len(model.named_steps[\"poly\"].get_feature_names_out([\"bmi\"]))\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results).sort_values(\"val_R2\", ascending=False)\n",
    "display(results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21a76d6b",
   "metadata": {},
   "source": [
    "## 8) Identify the best model (based on validation)\n",
    "\n",
    "Primary selection rule (simple + defensible):\n",
    "- Choose the model with **highest validation R²**\n",
    "- If very close, prefer **lower validation MAE** and simpler degree (to reduce overfitting risk).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e76652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the best degree by validation R2 (tie-breakers: MAE, simpler degree)\n",
    "results_sorted = results_df.sort_values([\"val_R2\", \"val_MAE\", \"degree\"], ascending=[False, True, True])\n",
    "best_row = results_sorted.iloc[0]\n",
    "best_degree = int(best_row[\"degree\"])\n",
    "best_model = models[best_degree]\n",
    "\n",
    "print(\"Best degree selected:\", best_degree)\n",
    "display(best_row.to_frame(\"best_model_summary\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a700917",
   "metadata": {},
   "source": [
    "## 9) Evaluate the chosen model on the **test set** (R², MAE, MAPE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd661a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test evaluation\n",
    "yhat_test = best_model.predict(X_test_bmi)\n",
    "test_m = regression_metrics(y_test, yhat_test)\n",
    "test_m\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6d2096",
   "metadata": {},
   "source": [
    "## 10) Plot train / validation / test points + model fit\n",
    "\n",
    "We plot all three splits and overlay the chosen polynomial curve.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7899240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot data and the chosen polynomial fit\n",
    "def plot_univariate_fit(model, X_train_bmi, y_train, X_val_bmi, y_val, X_test_bmi, y_test, title):\n",
    "    # grid for smooth curve\n",
    "    x_all = pd.concat([X_train_bmi, X_val_bmi, X_test_bmi])[\"bmi\"]\n",
    "    x_grid = np.linspace(x_all.min(), x_all.max(), 300).reshape(-1, 1)\n",
    "    x_grid_df = pd.DataFrame(x_grid, columns=[\"bmi\"])\n",
    "    y_grid = model.predict(x_grid_df)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.scatter(X_train_bmi[\"bmi\"], y_train, alpha=0.7, label=\"Train\")\n",
    "    plt.scatter(X_val_bmi[\"bmi\"], y_val, alpha=0.7, label=\"Validation\")\n",
    "    plt.scatter(X_test_bmi[\"bmi\"], y_test, alpha=0.7, label=\"Test\")\n",
    "    plt.plot(x_grid_df[\"bmi\"], y_grid, label=\"Model fit\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"BMI (standardized)\")\n",
    "    plt.ylabel(\"Progression (target)\")\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_univariate_fit(\n",
    "    best_model, X_train_bmi, y_train, X_val_bmi, y_val, X_test_bmi, y_test,\n",
    "    title=f\"Chosen Univariate Polynomial Fit (degree={best_degree})\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d253660b",
   "metadata": {},
   "source": [
    "## 11) Equation of the best model (2 decimal digits)\n",
    "\n",
    "We extract polynomial feature names and coefficients from the trained pipeline.\n",
    "\n",
    "> Note: BMI is **standardized** in this dataset, so the equation uses standardized BMI.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5238f665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract equation from the pipeline\n",
    "poly = best_model.named_steps[\"poly\"]\n",
    "lin = best_model.named_steps[\"linreg\"]\n",
    "\n",
    "feature_names = poly.get_feature_names_out([\"bmi\"])\n",
    "coefs = lin.coef_\n",
    "intercept = lin.intercept_\n",
    "\n",
    "# LinearRegression in sklearn with include_bias=True: the bias term may be captured in intercept; still OK.\n",
    "terms = []\n",
    "for name, c in zip(feature_names, coefs):\n",
    "    if name == \"1\":\n",
    "        # handled by intercept conceptually\n",
    "        continue\n",
    "    terms.append((name, c))\n",
    "\n",
    "# Build equation string\n",
    "eq = f\"y = {intercept:.2f}\"\n",
    "for name, c in terms:\n",
    "    sign = \"+\" if c >= 0 else \"-\"\n",
    "    eq += f\" {sign} {abs(c):.2f}*{name}\"\n",
    "\n",
    "print(\"Best model equation (approx.):\")\n",
    "print(eq)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "545f8e95",
   "metadata": {},
   "source": [
    "## 12) Predict progression for a BMI value of your choice\n",
    "\n",
    "Because BMI is standardized, a value like:\n",
    "- **bmi = 0.05** means slightly above the dataset mean.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d194a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmi_value = 0.05  # choose any standardized BMI value you want\n",
    "pred = best_model.predict(pd.DataFrame({\"bmi\":[bmi_value]}))[0]\n",
    "print(f\"Predicted progression for bmi={bmi_value} (standardized): {pred:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ef884f",
   "metadata": {},
   "source": [
    "## 13) How many trainable parameters in each model? (and why)\n",
    "\n",
    "For **univariate polynomial regression** of degree *d*, the polynomial feature vector includes:\n",
    "- 1 (bias), x, x², …, xᵈ  \n",
    "So the number of coefficients grows as **(d + 1)**.\n",
    "\n",
    "We show this directly using `get_feature_names_out()` (a practical way to see how many parameters/features are created).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002515e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_table = []\n",
    "for deg in range(0, 6):\n",
    "    feats = models[deg].named_steps[\"poly\"].get_feature_names_out([\"bmi\"])\n",
    "    param_table.append({\"degree\": deg, \"poly_features\": len(feats), \"feature_names\": \", \".join(feats)})\n",
    "\n",
    "param_df = pd.DataFrame(param_table)\n",
    "display(param_df[[\"degree\",\"poly_features\"]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb56781b",
   "metadata": {},
   "source": [
    "## 14) Conclusions for Part 2 (failure analysis + limitations)\n",
    "\n",
    "We do a short error analysis:\n",
    "- Residual plot (predicted vs residual)\n",
    "- Check where errors are larger (often at extremes)\n",
    "\n",
    "Talking points:\n",
    "- **Bias/variance:** higher degree can overfit train data and degrade validation.\n",
    "- **Metric trade‑offs:** R² can improve while MAPE/MAE might not improve equally.\n",
    "- **Limitations:** BMI alone ignores other clinical factors; screening tools must be used with caution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8827eb06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis on test set for univariate best model\n",
    "yhat_test = best_model.predict(X_test_bmi)\n",
    "residuals = y_test - yhat_test\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(yhat_test, residuals, alpha=0.7)\n",
    "plt.axhline(0)\n",
    "plt.title(\"Residuals vs Predicted (Test) — Univariate Best Model\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Residual (Actual - Predicted)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(residuals, bins=20)\n",
    "plt.title(\"Residual distribution (Test) — Univariate Best Model\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# A quick look at largest absolute errors\n",
    "err_df = pd.DataFrame({\n",
    "    \"bmi\": X_test_bmi[\"bmi\"].values,\n",
    "    \"actual\": y_test.values,\n",
    "    \"pred\": yhat_test,\n",
    "    \"abs_error\": np.abs(residuals.values)\n",
    "}).sort_values(\"abs_error\", ascending=False)\n",
    "\n",
    "display(err_df.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7caaf56",
   "metadata": {},
   "source": [
    "# Part 3 — Multivariate Models (all features) + Trees + kNN + Logistic Regression\n",
    "\n",
    "We repeat the core workflow:\n",
    "- Train on **train**\n",
    "- Select hyperparameters based on **validation**\n",
    "- Final evaluation on **test**\n",
    "\n",
    "Models:\n",
    "1. **Two polynomial models** (degrees > 1)\n",
    "2. **Two decision trees** (`max_depth` variations)\n",
    "3. **Two kNN regressors** (`k` variations)\n",
    "4. **Two Logistic Regression models** (binary “high‑risk” framing)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de10bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper: train+eval for regression models\n",
    "def eval_regression_model(name, model, X_tr, y_tr, X_val, y_val):\n",
    "    model.fit(X_tr, y_tr)\n",
    "    yhat_tr = model.predict(X_tr)\n",
    "    yhat_val = model.predict(X_val)\n",
    "    tr = regression_metrics(y_tr, yhat_tr)\n",
    "    va = regression_metrics(y_val, yhat_val)\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"train_R2\": tr[\"R2\"], \"train_MAE\": tr[\"MAE\"], \"train_MAPE(%)\": tr[\"MAPE(%)\"],\n",
    "        \"val_R2\": va[\"R2\"], \"val_MAE\": va[\"MAE\"], \"val_MAPE(%)\": va[\"MAPE(%)\"],\n",
    "    }\n",
    "\n",
    "reg_models = {}\n",
    "\n",
    "# --- 1) Two polynomial models (multivariate) ---\n",
    "# Note: full degree-3 on 10 features can create many features; we keep it reasonable and add regularization (Ridge).\n",
    "poly2_ridge = Pipeline(steps=[\n",
    "    (\"poly\", PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    (\"ridge\", Ridge(alpha=1.0, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "poly3_inter_ridge = Pipeline(steps=[\n",
    "    (\"poly\", PolynomialFeatures(degree=3, include_bias=False, interaction_only=True)),\n",
    "    (\"ridge\", Ridge(alpha=1.0, random_state=RANDOM_STATE))\n",
    "])\n",
    "\n",
    "reg_models[\"Poly2+Ridge\"] = poly2_ridge\n",
    "reg_models[\"Poly3(interactions)+Ridge\"] = poly3_inter_ridge\n",
    "\n",
    "# --- 2) Two decision trees ---\n",
    "tree_d3 = DecisionTreeRegressor(max_depth=3, random_state=RANDOM_STATE)\n",
    "tree_d6 = DecisionTreeRegressor(max_depth=6, random_state=RANDOM_STATE)\n",
    "reg_models[\"Tree(depth=3)\"] = tree_d3\n",
    "reg_models[\"Tree(depth=6)\"] = tree_d6\n",
    "\n",
    "# --- 3) Two kNN regressors ---\n",
    "knn3 = KNeighborsRegressor(n_neighbors=3)\n",
    "knn15 = KNeighborsRegressor(n_neighbors=15)\n",
    "reg_models[\"kNN(k=3)\"] = knn3\n",
    "reg_models[\"kNN(k=15)\"] = knn15\n",
    "\n",
    "# Evaluate on train + validation\n",
    "reg_results = []\n",
    "for name, model in reg_models.items():\n",
    "    reg_results.append(eval_regression_model(name, model, X_train, y_train, X_val, y_val))\n",
    "\n",
    "reg_results_df = pd.DataFrame(reg_results).sort_values(\"val_R2\", ascending=False)\n",
    "display(reg_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79160f0",
   "metadata": {},
   "source": [
    "## Pick best multivariate regression model + evaluate on test\n",
    "\n",
    "Selection rule: highest validation R² (tie-breaker: lower validation MAE).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "445c913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_results_sorted = reg_results_df.sort_values([\"val_R2\",\"val_MAE\"], ascending=[False, True])\n",
    "best_reg_name = reg_results_sorted.iloc[0][\"model\"]\n",
    "best_reg_model = reg_models[best_reg_name]\n",
    "\n",
    "print(\"Best multivariate regression model:\", best_reg_name)\n",
    "\n",
    "# Refit on train+val (common practice after selecting hyperparameters)\n",
    "X_trainval = pd.concat([X_train, X_val])\n",
    "y_trainval = pd.concat([y_train, y_val])\n",
    "\n",
    "best_reg_model.fit(X_trainval, y_trainval)\n",
    "yhat_test_reg = best_reg_model.predict(X_test)\n",
    "test_reg_metrics = regression_metrics(y_test, yhat_test_reg)\n",
    "\n",
    "test_reg_metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ad41a1",
   "metadata": {},
   "source": [
    "## Multivariate regression error analysis (where does it fail?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d80d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "resid_reg = y_test - yhat_test_reg\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(yhat_test_reg, resid_reg, alpha=0.7)\n",
    "plt.axhline(0)\n",
    "plt.title(f\"Residuals vs Predicted (Test) — {best_reg_name}\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Residual (Actual - Predicted)\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(resid_reg, bins=20)\n",
    "plt.title(f\"Residual distribution (Test) — {best_reg_name}\")\n",
    "plt.xlabel(\"Residual\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "err_df2 = pd.DataFrame({\n",
    "    \"actual\": y_test.values,\n",
    "    \"pred\": yhat_test_reg,\n",
    "    \"abs_error\": np.abs(resid_reg.values)\n",
    "}).sort_values(\"abs_error\", ascending=False)\n",
    "\n",
    "display(err_df2.head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f0e740",
   "metadata": {},
   "source": [
    "## Logistic Regression (classification framing)\n",
    "\n",
    "Because Logistic Regression is a classifier, we convert the continuous progression target into a **binary label**:\n",
    "- **High risk = 1** if progression ≥ median (computed on training data)\n",
    "- **Low risk = 0** otherwise\n",
    "\n",
    "This mirrors a realistic screening scenario: “flag patients likely to have higher progression”.\n",
    "\n",
    "We train **two Logistic Regression models** (different regularization strengths `C`) and evaluate on validation:\n",
    "- Accuracy, Precision, Recall, ROC‑AUC, Log‑Loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99da45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create binary target using median of TRAIN\n",
    "threshold = np.median(y_train)\n",
    "y_train_bin = (y_train >= threshold).astype(int)\n",
    "y_val_bin   = (y_val   >= threshold).astype(int)\n",
    "y_test_bin  = (y_test  >= threshold).astype(int)\n",
    "\n",
    "print(\"Threshold (median of train target):\", threshold)\n",
    "print(\"Train positive rate:\", y_train_bin.mean().round(3))\n",
    "print(\"Val positive rate:  \", y_val_bin.mean().round(3))\n",
    "print(\"Test positive rate: \", y_test_bin.mean().round(3))\n",
    "\n",
    "def eval_logistic(name, clf, X_tr, y_tr, X_val, y_val):\n",
    "    clf.fit(X_tr, y_tr)\n",
    "    p_tr = clf.predict_proba(X_tr)[:, 1]\n",
    "    p_val = clf.predict_proba(X_val)[:, 1]\n",
    "    yhat_tr = (p_tr >= 0.5).astype(int)\n",
    "    yhat_val = (p_val >= 0.5).astype(int)\n",
    "    return {\n",
    "        \"model\": name,\n",
    "        \"train_acc\": accuracy_score(y_tr, yhat_tr),\n",
    "        \"val_acc\": accuracy_score(y_val, yhat_val),\n",
    "        \"train_prec\": precision_score(y_tr, yhat_tr, zero_division=0),\n",
    "        \"val_prec\": precision_score(y_val, yhat_val, zero_division=0),\n",
    "        \"train_rec\": recall_score(y_tr, yhat_tr, zero_division=0),\n",
    "        \"val_rec\": recall_score(y_val, yhat_val, zero_division=0),\n",
    "        \"train_auc\": roc_auc_score(y_tr, p_tr),\n",
    "        \"val_auc\": roc_auc_score(y_val, p_val),\n",
    "        \"train_logloss\": log_loss(y_tr, p_tr),\n",
    "        \"val_logloss\": log_loss(y_val, p_val),\n",
    "    }\n",
    "\n",
    "# Two logistic regression models\n",
    "log1 = LogisticRegression(C=0.3, max_iter=500, random_state=RANDOM_STATE)\n",
    "log2 = LogisticRegression(C=3.0, max_iter=500, random_state=RANDOM_STATE)\n",
    "\n",
    "log_results = []\n",
    "log_results.append(eval_logistic(\"LogReg(C=0.3)\", log1, X_train, y_train_bin, X_val, y_val_bin))\n",
    "log_results.append(eval_logistic(\"LogReg(C=3.0)\", log2, X_train, y_train_bin, X_val, y_val_bin))\n",
    "\n",
    "log_results_df = pd.DataFrame(log_results).sort_values(\"val_auc\", ascending=False)\n",
    "display(log_results_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8baf9b7",
   "metadata": {},
   "source": [
    "### Logistic Regression — select best on validation ROC‑AUC and evaluate on test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3776dd72",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_log_name = log_results_df.iloc[0][\"model\"]\n",
    "best_log_model = log1 if best_log_name == \"LogReg(C=0.3)\" else log2\n",
    "print(\"Best logistic model:\", best_log_name)\n",
    "\n",
    "# Refit on train+val for final test evaluation\n",
    "y_trainval_bin = (y_trainval >= threshold).astype(int)\n",
    "best_log_model.fit(X_trainval, y_trainval_bin)\n",
    "\n",
    "p_test = best_log_model.predict_proba(X_test)[:, 1]\n",
    "yhat_test_bin = (p_test >= 0.5).astype(int)\n",
    "\n",
    "log_test_metrics = {\n",
    "    \"accuracy\": accuracy_score(y_test_bin, yhat_test_bin),\n",
    "    \"precision\": precision_score(y_test_bin, yhat_test_bin, zero_division=0),\n",
    "    \"recall\": recall_score(y_test_bin, yhat_test_bin, zero_division=0),\n",
    "    \"roc_auc\": roc_auc_score(y_test_bin, p_test),\n",
    "    \"log_loss\": log_loss(y_test_bin, p_test),\n",
    "}\n",
    "log_test_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96fdefc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix + ROC curve on test\n",
    "cm = confusion_matrix(y_test_bin, yhat_test_bin)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot()\n",
    "plt.title(\"Confusion Matrix (Test) — Logistic Regression\")\n",
    "plt.show()\n",
    "\n",
    "RocCurveDisplay.from_predictions(y_test_bin, p_test)\n",
    "plt.title(\"ROC Curve (Test) — Logistic Regression\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ceb1a3f",
   "metadata": {},
   "source": [
    "# Final Conclusions (overall)\n",
    "\n",
    "## What performed best?\n",
    "- Use the validation set to choose the best complexity / hyperparameters.\n",
    "- Report final metrics only once on the test set to avoid optimistic bias.\n",
    "\n",
    "## Where models fail (common patterns)\n",
    "- **Extreme progression values:** many models under‑predict very high progression and over‑predict very low progression (regression to the mean).\n",
    "- **Univariate BMI model limitation:** ignores other risk factors; can’t capture multi‑factor interactions.\n",
    "- **High‑degree polynomials:** can overfit (high variance) and become unstable at edges of the feature range.\n",
    "- **Decision trees:** can overfit if too deep; shallow trees may underfit (high bias).\n",
    "- **kNN:** sensitive to `k`; small `k` can chase noise, large `k` can oversmooth.\n",
    "\n",
    "## Practical limitations (screening tool context)\n",
    "- The dataset is a curated toy dataset, not a real clinical cohort (generalization limits).\n",
    "- The target is not a direct “risk probability”; it’s a continuous progression measure.\n",
    "- For real deployment, we would require:\n",
    "  - external validation on a separate hospital population\n",
    "  - fairness checks across patient subgroups\n",
    "  - calibration (especially for classification “high‑risk” probabilities)\n",
    "  - clinical oversight: models support decisions, not replace them\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
